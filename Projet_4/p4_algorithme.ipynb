{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies dont on aura besoin pour ce tp\n",
    "from math import sqrt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour ne pas avoir les warnings lors de la compilation\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Lieu où se trouve le fichier\n",
    "_DOSSIER = 'C:\\\\Users\\\\Toni\\\\Desktop\\\\'\n",
    "_DOSSIERPKL = 'C:\\\\Users\\\\Toni\\\\python\\\\python\\\\Projet_4\\\\pkl'\n",
    "_DOSSIERIMAGE = 'C:\\\\Users\\\\Toni\\\\python\\\\python\\\\Projet_4\\\\images'\n",
    "_FICHIERDATA = _DOSSIER + 'dataset_p4.csv'\n",
    "_VERBOSE = 10\n",
    "\n",
    "# Booléean pour faire la différence entre un fit et un joblib load\n",
    "_RECALCUL_JOBLIB = False\n",
    "_RECALCUL_JOBLIB_HYP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de calcul pour tous les algorithmes différents pour chaque compagnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lancer_algorithme(data):\n",
    "\n",
    "    # Logging for Visual Comparison\n",
    "    log_cols = [\"Classifier\", \"Id\", \"RMSE\", \"R2\"]\n",
    "    log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "    # Création de la liste (unique) des compagnies aériennes\n",
    "    liste = data['UNIQUE_CARRIER'].unique()\n",
    "\n",
    "    for compagnie in liste:\n",
    "\n",
    "        # Copie de sauvegarde\n",
    "        datanum = data.copy()\n",
    "\n",
    "        print('\\n\\nPour la compagnie', compagnie)\n",
    "\n",
    "        # On ne garde que les données pour 1 compagnie à la fois\n",
    "        datanum = datanum[datanum['UNIQUE_CARRIER'] == compagnie]\n",
    "\n",
    "        # Puis on supprime cette donnée car on sait qu'elle sera toujours la même\n",
    "        del datanum['UNIQUE_CARRIER']\n",
    "\n",
    "        # Axe X\n",
    "        data_x = datanum.copy()\n",
    "\n",
    "        # On supprime les étiquettes de l'axe X\n",
    "        del data_x['ARR_DELAY']\n",
    "\n",
    "        # Axe Y\n",
    "        data_y = datanum['ARR_DELAY']\n",
    "\n",
    "        # One-Hot encoding\n",
    "        liste_criteres = ['ORIGIN',\n",
    "                          'DEP_TIME_BLK',\n",
    "                          'DAY_OF_WEEK',\n",
    "                          'DEST',\n",
    "                          'MONTH']\n",
    "        data_x = pd.get_dummies(data=data_x, columns=liste_criteres)\n",
    "\n",
    "        # On supprime les nan\n",
    "        data_x.fillna(0, inplace=True)\n",
    "        data_y.fillna(0, inplace=True)\n",
    "\n",
    "        # Répartition Train/Test\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(data_x, data_y, train_size=0.75)\n",
    "\n",
    "        # Fonction qui va comparer les algorithmes sans optimisations\n",
    "        #log = algo_wo_optimisation(xtrain, xtest, ytrain, ytest, compagnie, log)\n",
    "\n",
    "        # Fonction qui permets de faire les CV\n",
    "        log_cv = appel_cvs(xtrain, ytrain, compagnie)\n",
    "\n",
    "    return log, log_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de différentes algorithmes sans optimisation recherchée, uniquement pour avoir une petite idée de ce qu'ils sont capables de faire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_wo_optimisation(xtrain, xtest, ytrain, ytest, compagnie, log):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    classifiers = [SGDRegressor(),\n",
    "                   AdaBoostRegressor(),\n",
    "                   LinearRegression(),\n",
    "                   ElasticNetCV(),\n",
    "                   LassoCV(),\n",
    "                   OrthogonalMatchingPursuitCV(),\n",
    "                   RidgeCV(),\n",
    "                   RandomForestRegressor()]\n",
    "\n",
    "    for clf in classifiers:\n",
    "\n",
    "        # Nom du classifieur\n",
    "        name = clf.__class__.__name__\n",
    "\n",
    "        # Localisation de du fichier du fit sauvegardé\n",
    "        fichier = _DOSSIERPKL + \"\\\\\" + name + \"_\" + compagnie + \".pkl\"\n",
    "\n",
    "        # Choix entre fit de nouveau ou aller chercher le fit sauvegardé\n",
    "        if _RECALCUL_JOBLIB is True:\n",
    "            # Fit\n",
    "            clf.fit(xtrain, ytrain)\n",
    "            # Dump (sauvegarde)\n",
    "            joblib.dump(clf, fichier)\n",
    "        else:\n",
    "            # On va chercher le dump\n",
    "            clf = joblib.load(fichier)\n",
    "\n",
    "        print(\"=\"*40)\n",
    "        print(name)\n",
    "\n",
    "        # Predictions\n",
    "        train_predictions = clf.predict(xtest)\n",
    "\n",
    "        # Scores des prédictions\n",
    "        mse = sqrt(abs(mean_squared_error(ytest, train_predictions)))\n",
    "        score2 = 100 * r2_score(ytest, train_predictions)\n",
    "\n",
    "        # Affichage des scores de prédictions\n",
    "        print(\"RMSE : \", round(mse, 4))\n",
    "        print(\"R2 : \", round(score2, 3))\n",
    "\n",
    "        # Sauvegarde des scores de predictions\n",
    "        log_entry = pd.DataFrame([[name, compagnie, mse, score2]], columns=log.columns)\n",
    "        log = log.append(log_entry)\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On appelle 4 regresseurs différentes avec leurs hyperparamètres, avant d'afficher les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appel_cvs(xtrain, ytrain, compagnie):\n",
    "\n",
    "    # Choix de l'algorithme de régression : SGDRegressor et hyperparamètres\n",
    "    model = SGDRegressor()\n",
    "    param_grid = [{'alpha' : 10.0**-np.arange(1, 7),\n",
    "                   'l1_ratio':[.05, .15, .5, .7, .9, .95, .99, 1]\n",
    "                  }]\n",
    "\n",
    "\n",
    "    # Appel de fonction avec le SGDRegressor\n",
    "    log_cv = algos_cv(xtrain, ytrain, model, param_grid, compagnie)\n",
    "\n",
    "     # Choix de l'algorithme de régression : Ridge et hyperparamètres\n",
    "    model = Ridge()\n",
    "    param_grid = {'alpha': np.logspace(-7, 7, 15)}\n",
    "\n",
    "    # Appel de fonction avec le Ridge\n",
    "    log_cv = algos_cv(xtrain, ytrain, model, param_grid, compagnie)\n",
    "\n",
    "    # Choix de l'algorithme de régression RFR et hyperparamètres\n",
    "    model = RandomForestRegressor()\n",
    "    param_grid = {'max_depth': range(3, 6),\n",
    "                  'min_samples_split': range(3, 6)}\n",
    "\n",
    "    # Appel de fonction avec le RandomForestRegressor\n",
    "    log_cv = algos_cv(xtrain, ytrain, model, param_grid, compagnie)\n",
    "\n",
    "    # Choix de l'algorithme de régression RFR et hyperparamètres\n",
    "    model = LassoCV()\n",
    "    param_grid = {'eps': [1e-2, 1e-3, 1e-4],\n",
    "                  'n_alphas': range(3, 6)}\n",
    "\n",
    "    # Appel de fonction avec le RandomForestRegressor\n",
    "    log_cv = algos_cv(xtrain, ytrain, model, param_grid, compagnie)\n",
    "\n",
    "    return log_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction qui va de pair avec celle du dessus, c'est celle-la qui fait les calculs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algos_cv(xtrain, ytrain, model, param_grid, compagnie):\n",
    "\n",
    "    # Score à améliorer\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Options de l'algorithme\n",
    "    clf = GridSearchCV(model,\n",
    "                       param_grid=param_grid,\n",
    "                       verbose=_VERBOSE,\n",
    "                       cv=5,\n",
    "                       scoring=score,\n",
    "                       refit=True,\n",
    "                       return_train_score=False)\n",
    "\n",
    "    # Localisation de du fichier du fit sauvegardé\n",
    "    fichier = _DOSSIERPKL + \"\\\\Hyp_\" + model.__class__.__name__ + \"_\" + compagnie + \".pkl\"\n",
    "\n",
    "    # Choix entre fit de nouveau ou aller chercher le fit sauvegardé\n",
    "    if _RECALCUL_JOBLIB_HYP is True:\n",
    "        # Fit\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        # Dump du fichier\n",
    "        joblib.dump(clf, fichier)\n",
    "    else:\n",
    "        # On va chercher le dump\n",
    "        clf = joblib.load(fichier)\n",
    "\n",
    "    # Liste qui va garder les résultats\n",
    "    log_cols = [\"RMSE\", \"Hyperparametres\"]\n",
    "    log_cv = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "    # Affichages\n",
    "    for mse, params in zip(clf.cv_results_['mean_test_score'], clf.cv_results_['params']):\n",
    "        print(\"RMSE : \", round(sqrt(abs(mse)), 4), \"pour\", params)\n",
    "\n",
    "        # Sauvegarde des scores de predictions\n",
    "        log_entry = pd.DataFrame([[sqrt(abs(mse)), params]], columns=log_cv.columns)\n",
    "        log_cv = log_cv.append(log_entry)\n",
    "\n",
    "    # Meilleurs paramètres\n",
    "    score_max = round(sqrt(abs(clf.best_score_)), 4)\n",
    "    print(\"\\nMeilleur score : \", score_max, \"pour\", clf.best_params_)\n",
    "\n",
    "    # Affichage du diagramme en baton\n",
    "    affichage_rmse(model, log_cv, compagnie)\n",
    "\n",
    "    return log_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagrammes en batons pour voir les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage_rmse(model, log_cv, compagnie):\n",
    "\n",
    "    # Mise en forme légère\n",
    "    log_cv = log_cv.reset_index()\n",
    "    del log_cv['index']\n",
    "\n",
    "    # Noms des variables\n",
    "    data_colonne = log_cv['RMSE']\n",
    "    data_ligne = log_cv['Hyperparametres']\n",
    "\n",
    "    # La figure change de taille suivant le nombre de données\n",
    "    plt.figure(figsize=(len(data_colonne), 8))\n",
    "\n",
    "    # Données de l'axe X\n",
    "    x_axis = [k for k, i in enumerate(data_colonne)]\n",
    "    x_label = [i for i in data_ligne]\n",
    "\n",
    "    # Données de l'axe Y\n",
    "    y_axis = [i for i in data_colonne]\n",
    "\n",
    "    # Limite de l'axe Y\n",
    "    plt.ylim(min(log_cv['RMSE'])-0.5, max(log_cv['RMSE'])+0.5)\n",
    "\n",
    "    # Largeur des barres\n",
    "    width = 0.2\n",
    "\n",
    "    # Légende de l'axe X\n",
    "    plt.xticks(x_axis, x_label, rotation=90)\n",
    "\n",
    "    # Création\n",
    "    rects = plt.bar(x_axis, y_axis, width, color='b')\n",
    "\n",
    "    # On fait les labels pour les afficher\n",
    "    labels = [\"%.2f\" % i for i in data_colonne]\n",
    "\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        width = rect.get_width()\n",
    "\n",
    "        plt.text(rect.get_x()+ width/2, height + 0.1, label, ha='center', va='bottom')\n",
    "\n",
    "    # Barres horizontales\n",
    "    plt.axhline(y=sum(data_colonne)/len(data_colonne), color='r', linestyle='-')\n",
    "    plt.axhline(y=min(data_colonne), color='g', linestyle='-')\n",
    "\n",
    "    # Esthétisme\n",
    "    plt.grid()\n",
    "    plt.ylabel('RMSE')\n",
    "    titre = 'RMSE suivant les hyperparamètres pour ' + compagnie\n",
    "    plt.title(titre)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(_DOSSIERIMAGE + \"\\\\_RMSE_\" + model.__class__.__name__ + \"_\" + compagnie)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagrammes en batons pour voir les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage_resultats(log_pivot):\n",
    "\n",
    "    for nom_colonne in log_pivot:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        data_colonne = log_pivot[nom_colonne]\n",
    "\n",
    "        # Données de l'axe X\n",
    "        x_axis = [k for k, i in enumerate(data_colonne)]\n",
    "        x_label = [i for i in data_colonne.index]\n",
    "\n",
    "        # Données de l'axe Y\n",
    "        y_axis = [i for i in data_colonne]\n",
    "\n",
    "        # Largeur des barres\n",
    "        width = 0.2\n",
    "\n",
    "        # Légende de l'axe X\n",
    "        plt.xticks(x_axis, x_label, rotation=90)\n",
    "\n",
    "        # Création\n",
    "        rects = plt.bar(x_axis, y_axis, width, color='b')\n",
    "\n",
    "        # On fait les labels pour les afficher\n",
    "        labels = [\"%.2f\" % i for i in data_colonne]\n",
    "\n",
    "        for rect, label in zip(rects, labels):\n",
    "            height = rect.get_height()\n",
    "            width = rect.get_width()\n",
    "\n",
    "            plt.text(rect.get_x()+ width/2, height + 0.1, label, ha='center', va='bottom')\n",
    "\n",
    "        # Barres horizontales\n",
    "        plt.axhline(y=sum(data_colonne)/len(data_colonne), color='r', linestyle='-')\n",
    "        plt.axhline(y=min(data_colonne), color='g', linestyle='-')\n",
    "\n",
    "        # Esthétisme\n",
    "        plt.grid()\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(nom_colonne)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(_DOSSIERIMAGE + \"//_Bar_\" + nom_colonne)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Récupération des dataset\n",
    "data = pd.read_csv(_FICHIERDATA, error_bad_lines=False, low_memory=False)\n",
    "del data['Unnamed: 0']\n",
    "\n",
    "# Premier algorithme\n",
    "log, log_cv = lancer_algorithme(data)\n",
    "\n",
    "# Affichages\n",
    "print(log)\n",
    "print(log_cv)\n",
    "\n",
    "# On enlève un regresseur hors-norme\n",
    "log = log[log['Classifier'] != 'LinearRegression']\n",
    "\n",
    "# Affichages\n",
    "affichage_resultats(log.pivot(index='Id', columns='Classifier', values='RMSE'))\n",
    "affichage_resultats(log.pivot(index='Classifier', columns='Id', values='RMSE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
